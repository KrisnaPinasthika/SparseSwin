{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision import datasets\n",
    "import numpy as np \n",
    "import build_model as build\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import build_model as build\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swin Transformer - Stage 4 params : 4575.6250\n",
      "SparTa Block params: 2101.7261\n"
     ]
    }
   ],
   "source": [
    "# Number of parameters at stage 4 Swin Transformer\n",
    "calc = 0\n",
    "for i in models.swin_t().features[6:].parameters():\n",
    "    calc += i.sum()\n",
    "\n",
    "print(f\"Swin Transformer - Stage 4 params : {calc:.4f}\")\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = build.buildSparseSwin(\n",
    "        image_resolution=224,\n",
    "        swin_type='tiny', \n",
    "        num_classes=100, \n",
    "        ltoken_num=49, \n",
    "        ltoken_dims=512, \n",
    "        num_heads=16, \n",
    "        qkv_bias=True,\n",
    "        lf=2, \n",
    "        attn_drop_prob=.0, \n",
    "        lin_drop_prob=.0, \n",
    "        freeze_12=False,\n",
    "        device=device)\n",
    "\n",
    "calc = 0\n",
    "for i in model.step4.parameters():\n",
    "    calc += i.sum()\n",
    "\n",
    "print(f\"SparTa Block params: {calc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "def getModel(sparse_swin_type, num_classes): \n",
    "    sparse_swin_type = sparse_swin_type.lower()\n",
    "    if sparse_swin_type == 'tiny':\n",
    "        ltoken_num, ltoken_dims = 49, 512\n",
    "    elif sparse_swin_type == 'small':\n",
    "        ltoken_num, ltoken_dims = 64, 768\n",
    "    elif sparse_swin_type == 'base':\n",
    "        ltoken_num, ltoken_dims = 81, 1024\n",
    "    else:\n",
    "        print(f\"Unknown SparseSwin Model..\")\n",
    "        return None\n",
    "    \n",
    "    model = build.buildSparseSwin(\n",
    "            image_resolution=224,\n",
    "            swin_type='tiny', \n",
    "            num_classes=num_classes, \n",
    "            ltoken_num=ltoken_num, \n",
    "            ltoken_dims=ltoken_dims, \n",
    "            num_heads=16, \n",
    "            qkv_bias=True,\n",
    "            lf=2, \n",
    "            attn_drop_prob=.0, \n",
    "            lin_drop_prob=.0, \n",
    "            freeze_12=False,\n",
    "            device=device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseSwin-tiny\n",
      "GFlops:  6.22\n",
      "Params: 20.29 M\n",
      "\n",
      "SparseSwin-small\n",
      "GFlops:  7.78\n",
      "Params: 29.07 M\n",
      "\n",
      "SparseSwin-base\n",
      "GFlops:  10.40\n",
      "Params: 41.00 M\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "for sparse_swin_type in ['tiny', 'small', 'base']:\n",
    "    print(f\"SparseSwin-{sparse_swin_type}\")\n",
    "    with torch.cuda.device(0):\n",
    "        net =  getModel(sparse_swin_type=sparse_swin_type, num_classes=100)\n",
    "        # net = models.swin_t()\n",
    "        flops, params = get_model_complexity_info(net, (3, 224, 224), \n",
    "                                                    as_strings=False, print_per_layer_stat=False, \n",
    "                                                    flops_units='GMac', output_precision=4)\n",
    "        print(f'GFlops:  {2 * flops * 1e-9:.2f}')\n",
    "        print(f'Params: {params * 1e-6:.2f} M')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 and CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataset Config -------------------------------------------\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transform = {\n",
    "    'train': transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]), \n",
    "    'val': transforms.Compose([\n",
    "                transforms.ToTensor(), \n",
    "                transforms.Resize((224, 224), antialias=None),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "}\n",
    "\n",
    "status = True\n",
    "batch_size = 32\n",
    "dataset_name, dataset_classes = 'cifar10', 10\n",
    "val_dataset = datasets.CIFAR10(\n",
    "                    root='./datasets/torch_cifar10/', \n",
    "                    train=False, \n",
    "                    transform=data_transform['val'], \n",
    "                    download=status)\n",
    "\n",
    "# val_dataset = datasets.CIFAR100(\n",
    "#                 root='./datasets/torch_cifar100/', \n",
    "#                 train=False, \n",
    "#                 transform=data_transform['val'], \n",
    "#                 download=status)\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "                val_dataset, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=True\n",
    "            )\n",
    "\n",
    "class2idx = val_dataset.class_to_idx\n",
    "idx2class = {class2idx[i]: i for i in val_dataset.class_to_idx.keys()}\n",
    "\n",
    "loader_iterate = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR100\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./datasets/torch_cifar100/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               Normalize(mean=[0.485 0.456 0.406], std=[0.229 0.224 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = False\n",
    "# Todo: Train on CIFAR10\n",
    "train_dataset = datasets.CIFAR10(\n",
    "                root='./datasets/torch_cifar10/', \n",
    "                train=True, \n",
    "                transform=data_transform['train'], \n",
    "                download=status)\n",
    "val_dataset = datasets.CIFAR10(\n",
    "                root='./datasets/torch_cifar10/', \n",
    "                train=False, \n",
    "                transform=data_transform['val'], \n",
    "                download=status)\n",
    "\n",
    "# Todo: Train on CIFAR100\n",
    "train_dataset = datasets.CIFAR100(\n",
    "                root='./datasets/torch_cifar100/', \n",
    "                train=True, \n",
    "                transform=data_transform['train'], \n",
    "                download=status)\n",
    "val_dataset = datasets.CIFAR100(\n",
    "                root='./datasets/torch_cifar100/', \n",
    "                train=False, \n",
    "                transform=data_transform['val'], \n",
    "                download=status)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data, sample_labels = next(loader_iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_paths = [\n",
    "    'SparseSwin_reg_None_lbd_0_lf_2_49.pt',\n",
    "    'SparseSwin_reg_l1_lbd_0.0001_lf_2_49.pt',\n",
    "    'SparseSwin_reg_l1_lbd_1e-05_lf_2_49.pt',\n",
    "    'SparseSwin_reg_l2_lbd_0.0001_lf_2_49.pt',\n",
    "    'SparseSwin_reg_l2_lbd_1e-05_lf_2_49.pt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeatMap(heatmap):\n",
    "\n",
    "    h_shape, w_shape = 224, 224\n",
    "\n",
    "    h_min, h_max = heatmap.min(), heatmap.max()\n",
    "    norm_map = 255 * ((heatmap - h_min) / (h_max - h_min))\n",
    "    norm_map = np.uint8(norm_map)\n",
    "    norm_map = cv2.resize(norm_map, (h_shape, w_shape)) \n",
    "    \n",
    "    norm_map = cv2.applyColorMap(255 - norm_map, cv2.COLORMAP_JET)\n",
    "    norm_map = np.uint8(norm_map)\n",
    "\n",
    "    return norm_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for saved_path in saved_model_paths:\n",
    "    print(saved_path)\n",
    "    \n",
    "    #Todo: Model preparation\n",
    "    model = getModel(sparse_swin_type='tiny', num_classes=dataset_classes)\n",
    "    im2fmap = nn.Sequential(model.swin_model, model.step4)\n",
    "\n",
    "    model.load_state_dict(torch.load(f'./SavedModel/{dataset_name}/{saved_path}'))\n",
    "    \n",
    "    #Todo: Model test\n",
    "    model.eval()\n",
    "    logits, attn_weight1, origin = model(sample_data.to(device))\n",
    "    heatmaps = []\n",
    "\n",
    "    activations, attn_weight2, origin = im2fmap(sample_data.to(device))\n",
    "\n",
    "    # get model preds\n",
    "    pred = logits.max(-1)[-1]\n",
    "    model.zero_grad()\n",
    "    # compute gradients with respect to model's most confident logit\n",
    "    logits[0, pred].mean().backward(retain_graph=True)\n",
    "        \n",
    "    # Get the gradients at the required featuremap location and take avg gradient\n",
    "    pooled_grads = model.step4.convert_token.convert.weight.data.mean((1, 2, 3))\n",
    "    # print(pooled_grads.shape)\n",
    "\n",
    "    # multiply each activation map with\n",
    "    # corresponding gradient average\n",
    "\n",
    "    for i in range(activations.shape[2]): \n",
    "        origin[:, i, :, :] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = torch.mean(origin, dim=1).cpu().detach()\n",
    "    \n",
    "    inv_normalize = transforms.Normalize(\n",
    "                    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "                    std=[1/0.229, 1/0.224, 1/0.225]\n",
    "                    )\n",
    "    inv_tensor = inv_normalize(sample_data)\n",
    "    \n",
    "    show_idx = 0\n",
    "    sample_predics = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    for show_idx in range(batch_size):\n",
    "        viz_heatmap = getHeatMap(heatmap[show_idx])\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 3.75))\n",
    "        \n",
    "        name_tmp = saved_path.split('_')\n",
    "\n",
    "        if name_tmp[2] == 'None':\n",
    "            name = f\"{name_tmp[0]}\"\n",
    "        else:\n",
    "            name = f\"{name_tmp[0]} with {name_tmp[2].upper()} ({'1e-4' if name_tmp[4] == '0.0001' else '1e-5'})\"\n",
    "            \n",
    "        # print(name)\n",
    "        \n",
    "        fig.suptitle(name, fontsize=18, color='orange')\n",
    "        \n",
    "        temp_inv_tensor = inv_tensor[show_idx].permute(1, 2, 0)\n",
    "        \n",
    "        ax[0].set_title(f'Ground Truth: { idx2class[sample_labels[show_idx].item()] }')\n",
    "        ax[1].set_title(f'Grad-CAM')\n",
    "        ax[2].set_title(f'Prediction: { idx2class[sample_predics[show_idx].item()] }')\n",
    "        \n",
    "        ax[0].imshow(temp_inv_tensor)\n",
    "        ax[1].imshow(viz_heatmap)\n",
    "        ax[2].imshow(temp_inv_tensor + ((viz_heatmap/255)*0.35))\n",
    "        \n",
    "        # plt.show()\n",
    "        plt.savefig(f'./gradcam/{dataset_name}/{name}_{show_idx}.png')\n",
    "    \n",
    "    \n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet-100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import build_model as build\n",
    "from traintest import train, test\n",
    "from torchvision.models.swin_transformer import swin_t, Swin_T_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "def getModel(sparse_swin_type, num_classes): \n",
    "    sparse_swin_type = sparse_swin_type.lower()\n",
    "    if sparse_swin_type == 'tiny':\n",
    "        ltoken_num, ltoken_dims = 49, 512\n",
    "    elif sparse_swin_type == 'small':\n",
    "        ltoken_num, ltoken_dims = 64, 768\n",
    "    elif sparse_swin_type == 'base':\n",
    "        ltoken_num, ltoken_dims = 81, 1024\n",
    "    else:\n",
    "        print(f\"Unknown SparseSwin Model..\")\n",
    "        return None\n",
    "    \n",
    "    model = build.buildSparseSwin(\n",
    "            image_resolution=224,\n",
    "            swin_type='tiny', \n",
    "            num_classes=num_classes, \n",
    "            ltoken_num=ltoken_num, \n",
    "            ltoken_dims=ltoken_dims, \n",
    "            num_heads=16, \n",
    "            qkv_bias=True,\n",
    "            lf=2, \n",
    "            attn_drop_prob=.0, \n",
    "            lin_drop_prob=.0, \n",
    "            freeze_12=False,\n",
    "            device=device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imagenet100(torch.utils.data.Dataset):\n",
    "    \"\"\"Some Information about Imagenet100\"\"\"\n",
    "    def __init__(self, df, class2idx, transform):\n",
    "        super(Imagenet100, self).__init__()\n",
    "        self.df = df\n",
    "        self.class2idx = class2idx\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.df['image_path'].iloc[index], self.df['label'].iloc[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform: \n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = torch.tensor(self.class2idx[label], dtype=torch.long)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "def get_path(list_paths):\n",
    "    filelist = []\n",
    "\n",
    "    for root_path in list_paths:\n",
    "        for dir in os.listdir(root_path):\n",
    "            dir_path = os.path.join(root_path, dir)\n",
    "            # count = 0\n",
    "            for data in os.listdir(dir_path):\n",
    "                if data.lower().split('.')[-1] != 'jpeg': \n",
    "                    continue\n",
    "                data_path = os.path.join(dir_path, data)\n",
    "                filelist.append([data_path, dir])\n",
    "                # count += 1\n",
    "\n",
    "    df = pd.DataFrame(filelist, columns=['image_path', 'label'])\n",
    "    class2idx = {label:i for i, label in enumerate(sorted(set(df['label'])))}\n",
    "    return df, class2idx\n",
    "\n",
    "def load(df, class2idx, batch_size, type_transforms): \n",
    "    \n",
    "    if type_transforms == 'train':\n",
    "        transform_new=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        transform_new=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(256, antialias=None),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    \n",
    "    return DataLoader(\n",
    "            dataset=Imagenet100(\n",
    "                df=df, \n",
    "                class2idx=class2idx, \n",
    "                transform=transform_new),\n",
    "            batch_size=batch_size, \n",
    "            shuffle=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = [r'../datasets/imagenet100/train.X1/', \n",
    "                r'../datasets/imagenet100/train.X2/', \n",
    "                r'../datasets/imagenet100/train.X3/', \n",
    "                r'../datasets/imagenet100/train.X4/']\n",
    "\n",
    "test_paths = [r'../datasets/imagenet100/val.X/']\n",
    "\n",
    "train_df, train_class2idx = get_path(train_paths)\n",
    "test_df, test_class2idx = get_path(test_paths)\n",
    "\n",
    "# Todo: Check the label\n",
    "with open('../datasets/imagenet100/Labels.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "class2idx = {j:i for i, j in enumerate(sorted(data.keys()))}\n",
    "idx2class = {class2idx[i]: i for i in class2idx.keys()}\n",
    "\n",
    "if (train_class2idx != class2idx):\n",
    "    print('Something wrong with class label, please check it immediately')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "val_loader = load(test_df, test_class2idx, batch_size=batch_size, type_transforms='test')\n",
    "loader_iterate = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    sample_data, sample_labels = next(loader_iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_paths = [\n",
    "    'SparseSwin_reg_None_lbd_0_lf_2_49',\n",
    "    # 'SparseSwin_reg_None_lbd_0_lf_2_64',\n",
    "    # 'SparseSwin_reg_None_lbd_0_lf_2_81',\n",
    "    \n",
    "    'SparseSwin_reg_l1_lbd_0.0001_lf_2_49',\n",
    "    # 'SparseSwin_reg_l1_lbd_0.0001_lf_2_64',\n",
    "    # 'SparseSwin_reg_l1_lbd_0.0001_lf_2_81',\n",
    "    \n",
    "    'SparseSwin_reg_l1_lbd_1e-05_lf_2_49',\n",
    "    # 'SparseSwin_reg_l1_lbd_1e-05_lf_2_64',\n",
    "    # 'SparseSwin_reg_l1_lbd_1e-05_lf_2_81',\n",
    "    \n",
    "    'SparseSwin_reg_l2_lbd_0.0001_lf_2_49',\n",
    "    # 'SparseSwin_reg_l2_lbd_0.0001_lf_2_64',\n",
    "    # 'SparseSwin_reg_l2_lbd_0.0001_lf_2_81',\n",
    "    \n",
    "    'SparseSwin_reg_l2_lbd_1e-05_lf_2_49',\n",
    "    # 'SparseSwin_reg_l2_lbd_1e-05_lf_2_64',\n",
    "    # 'SparseSwin_reg_l2_lbd_1e-05_lf_2_81',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeatMap(heatmap):\n",
    "\n",
    "    h_shape, w_shape = 224, 224\n",
    "\n",
    "    h_min, h_max = heatmap.min(), heatmap.max()\n",
    "    norm_map = 255 * ((heatmap - h_min) / (h_max - h_min))\n",
    "    norm_map = np.uint8(norm_map)\n",
    "    norm_map = cv2.resize(norm_map, (h_shape, w_shape)) \n",
    "    \n",
    "    norm_map = cv2.applyColorMap(255 - norm_map, cv2.COLORMAP_JET)\n",
    "    norm_map = np.uint8(norm_map)\n",
    "\n",
    "    return norm_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-Cam ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for saved_path in saved_model_paths:\n",
    "    print(saved_path)\n",
    "    \n",
    "    #Todo: Model preparation\n",
    "    model = getModel(sparse_swin_type='tiny', num_classes=100)\n",
    "    im2fmap = nn.Sequential(model.swin_model, model.step4)\n",
    "    \n",
    "    model_path = sorted(os.listdir(f\"./SavedModel/imagenet100/{saved_path}\"))[-1]\n",
    "    model.load_state_dict(torch.load(f'./SavedModel/imagenet100/{saved_path}/{model_path}'))\n",
    "    \n",
    "    #Todo: Model test\n",
    "    model.eval()\n",
    "    logits, attn_weight1, origin = model(sample_data.to(device))\n",
    "    heatmaps = []\n",
    "\n",
    "    activations, attn_weight2, origin = im2fmap(sample_data.to(device))\n",
    "\n",
    "    # get model preds\n",
    "    pred = logits.max(-1)[-1]\n",
    "    model.zero_grad()\n",
    "    logits[0, pred].mean().backward(retain_graph=True)\n",
    "        \n",
    "    pooled_grads = model.step4.convert_token.convert.weight.data.mean((1, 2, 3))\n",
    "\n",
    "    for i in range(activations.shape[2]): \n",
    "        origin[:, i, :, :] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = torch.mean(origin, dim=1).cpu().detach()\n",
    "    \n",
    "    inv_normalize = transforms.Normalize(\n",
    "                    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "                    std=[1/0.229, 1/0.224, 1/0.225]\n",
    "                    )\n",
    "    inv_tensor = inv_normalize(sample_data)\n",
    "    \n",
    "    show_idx = 0\n",
    "    sample_predics = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    for show_idx in range(batch_size):\n",
    "        viz_heatmap = getHeatMap(heatmap[show_idx])\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 3.75))\n",
    "        \n",
    "        name_tmp = saved_path.split('_')\n",
    "\n",
    "        if name_tmp[2] == 'None':\n",
    "            name = f\"{name_tmp[0]}\"\n",
    "        else:\n",
    "            name = f\"{name_tmp[0]} with {name_tmp[2].upper()} ({'1e-4' if name_tmp[4] == '0.0001' else '1e-5'})\"\n",
    "            \n",
    "        # print(name)\n",
    "        \n",
    "        fig.suptitle(name, fontsize=18, color='orange')\n",
    "        \n",
    "        temp_inv_tensor = inv_tensor[show_idx].permute(1, 2, 0)\n",
    "        gt_name = data[ idx2class[sample_labels[show_idx].item()] ].split(',')[0]\n",
    "        ax[0].set_title(f'Ground Truth: { gt_name }')\n",
    "        ax[1].set_title(f'Grad-CAM')\n",
    "        pred_name = data[idx2class[sample_predics[show_idx].item()] ].split(',')[0]\n",
    "        ax[2].set_title(f'Prediction: {pred_name}')\n",
    "        \n",
    "        ax[0].imshow(temp_inv_tensor)\n",
    "        ax[1].imshow(viz_heatmap)\n",
    "        ax[2].imshow(temp_inv_tensor + ((viz_heatmap/255)*0.35))\n",
    "        \n",
    "        # plt.show()\n",
    "        plt.savefig(f'./gradcam/imagenet100/{name}_{show_idx}.png')\n",
    "    \n",
    "    \n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "def complex_swin(h, w, c, m): \n",
    "    return (4 * h * w * c**2) + (2 * m**2 * h * w * c)\n",
    "\n",
    "def complex_sparta(t, e): \n",
    "    return (4 * t * e**2) + 2*t**2 * e \n",
    "\n",
    "history = []\n",
    "for i in range(0, 17): \n",
    "    swin = complex_swin(h= i, w=i, c=768, m=7)\n",
    "    sparta_tiny = complex_sparta(t=49, e=512)\n",
    "    sparta_small = complex_sparta(t=64, e=768)\n",
    "    sparta_base = complex_sparta(t=81, e=1024)\n",
    "    history.append([swin, sparta_tiny, sparta_small, sparta_base])\n",
    "\n",
    "history = np.array(history)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['swin'] = history[:, 0]\n",
    "df['sparta_tiny'] = history[:, 1]\n",
    "df['sparta_small'] = history[:, 2]\n",
    "df['sparta_base'] = history[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAArUUlEQVR4nO3deVyVZf7/8dcFIiggKiiiKCjuAoK4lWUSVlqmTVNjlpktY8vUtNfUzGQ1NdPe9J22cSy1NLWcVtNsGVBLcw1RwR01VhVllf1cvz84+jNjOch9zn0fzuf5ePBgOefc530O8ObiPvd9XUprjRBCCOvyMjuAEEKIxklRCyGExUlRCyGExUlRCyGExUlRCyGExUlRCyGExTmtqJVS7yqljiildjhw3V5KqWSl1E9KqTSl1OXOyiWEEO7GmSPq+cAEB6/7F+BDrXU8cB3wprNCCSGEu3FaUWut1wDHz/yaUipKKfWVUmqLUmqtUmrgqasDHewfBwE5zsolhBDupo2L728OcIfWeq9SahR1I+eLgSeBr5VS9wD+wHgX5xJCCMtyWVErpQKA84GPlFKnvuxrfz8NmK+1flkpdR7wvlIqWmttc1U+IYSwKleOqL2AQq11XD2X3Yp9f7bWer1Syg8IAY64Lp4QQliTyw7P01oXA5lKqWsBVJ2h9osPA0n2rw8C/ICjrsomhBBWppw1e55SajEwjrqRcT4wG/gf8BYQBvgAS7TWTyulBgP/AQKoe2HxEa31104JJoQQbsZpRS2EEMIYcmaiEEJYnFNeTAwJCdGRkZGGbrOsrAx/f39Dt2k0d8gIktNoktNY7pDTGRm3bNlyTGvdpd4LtdaGvyUkJGijJScnG75No7lDRq0lp9Ekp7HcIaczMgKbdQOdKrs+hBDC4qSohRDC4qSohRDC4lx2ZmJ1dTVZWVlUVFSc0+2DgoLIyMgwOJWxnJHRz8+P8PBwfHx8DN2uEMJ9uKyos7KyCAwMJDIykjPm+nBYSUkJgYGBTkhmHKMzaq0pKCggKyuL3r17G7ZdIYR7cdmuj4qKCoKDg8+ppD2VUorg4OBz/i9ECNE6uHQftZR088lzJoSQFxOFEKIZik5WsyijkpNVNS67T48q6meffZYhQ4YQGxtLXFwcGzZsaPI2TzzxBN9++61D23/ggQeIi4tj8ODBtGvXjri4OOLi4li2bFlLowshLKCyppZZ728m+XANu/JKXHa/rl7hxTTr169n+fLlbN26FV9fX44dO0ZVVVWTt3v66acdvo9XXnmFwMBADh48yKRJk0hNTW1BYiGEldhsmoc/SmND5nFuj/VlWK9OLrtvjxlR5+bmEhISgq9v3aIyISEhZGdnc/XVVwPw2Wef0a5dO6qqqqioqKBPnz4AzJw58/SIODIyktmzZzNs2DBiYmLYtWuXOQ9GCOFyL329m8+35fDwZQM4r7trx7imjKif+mIn6TnFzbpNbW0t3t7eDV4+uHsHZl85pMHLL730Up5++mn69+/P+PHjmTp1KmPGjDk96l27di3R0dFs2rSJmpoaRo0aVe92QkJC2Lp1K2+++SYvvfQSc+fObdbjEEK4nw82HObNlP1MG9mLu8ZFsXp1lkvv36ERtVKqo1JqmVJql1Iqw76uoVsJCAhgy5YtzJkzhy5dujB16lQWLlxIVFQUGRkZbNy4kQceeIA1a9awdu1aLrzwwnq3c2oEnpCQwMGDB134CIQQZkjedYS/fraDxAFd+NuUIaYcieXoiPo14Cut9TVKqbZA+5bcaWMj34YYcTKJt7c348aNY9y4ccTExLBgwQLGjh3LypUr8fHxYfz48cycOZPa2lpefPHFerdxateJt7c3NTV1r/pedtll5OfnM3ToUBYsWNCijEII69iRXcQfPtjKoLBAXr9+GG28zdlb3GRRK6WCgLHATACtdRXQ9KtwFrN79268vLzo168fAKmpqURERHDhhRcyY8YMZsyYQZcuXSgoKCA/P5/o6GiHt71q1Sqg7o+JEKJ1yDpxkpvnb6JT+7a8e9MI/H3NO/bCkXvuTd1Cs/Psi9FuAe7VWpc5NZnBSktLueeeeygsLKRNmzb07duXOXPm4O/vT35+PmPHjgUgNjaWvLw8OdFECA9WVF7NzfM2UVFdy6LbRtG1g5+peZpcM1EpNRz4ERijtd6glHoNKNZa//Ws680CZgGEhoYmLFmy5BfbCQoKom/fvucctKkXE63AWRn37dtHUVGRYdsrLS0lICDAsO05i+Q0luR0TLVN8/LmCvaesPHQcD8GBf/6d9oZGRMTE7dorYfXe2FDKwqcegO6AQfP+PxC4MvGblPfCi/p6ektWv2guLi4Rbd3BWdlbOlzdzZ3WEFDa8lpNMnZNJvNpu9dvFVHPLpcf7I1q8HrWW6FF611HvCzUmqA/UtJQLoBf0CEEMJSXv56D5+m1h0rfVV8D7PjnObo3vF7gEX2Iz4OADc7L5IQQrje4o2HeT15H9eN6Mld46LMjvMLDhW11joVqH/fiRBCuLnk3Uf4y6c7uKh/F/52VbTlDibwmFPIhRCiPjuyi7h70VYGhAbyxg3D8DHpWOnGWC+REEK4SHZhObfM30RQOx/m3TyCABOPlW6MRxX1uUxz2phVq1adnso0ICCAYcOGERcXx4wZMxq8TUFBwenbdOvWjR49epz+3JHZ/IQQxqg7Vnoj5VW1zLt5JKEmHyvdGGv++XCCc53mtDFJSUmnJ3UaN24cTz31FBdddFGjtwkODj59myeffJKAgAAeeuihFuUQQjRPVY2NO97fQuaxMhbcPJIB3ay9HqvHjKjrm+a0e/fuREZG8sgjjxATE8PIkSPZt28fAF988QWjRo0iPj6e8ePHk5+fD9SV64033siYMWO48cYb672vO++8k+HDhzNkyBBmz57tmgcohHCI1po//TeN9QcKeP63sZzfN8TsSE0yZ0S98k+Qt71ZN2lXWwPejcTtFgMTn2vw4vqmOT01+g0KCmL79u2899573HfffSxfvpwLLriAH3/8EaUUc+fO5YUXXuDll18GID09ne+//5527drVe1/PPvssnTt3pra2lqSkJNLS0oiNjW3W4xVCOMer3+zh45+yefCS/lw9LNzsOA7xmF0fp6Y5Xbt2LcnJyUydOpXnnqsr9mnTpp1+f//99wOQlZXF1KlTyc3Npaqqit69e5/e1uTJkxssaYAPP/yQOXPmUFNTQ25uLunp6VLUQljA0k2H+b//7WPq8J7cffG5T2nhauYUdSMj34aUO2maU/jlSt+nPr7nnnt44IEHmDx5MikpKTz55JOnr+Pv79/gfWRmZvLSSy+xadMmOnXqxMyZM6moqGDDhg3cfvvtQN3yXpMnT27RYxFCNM/qPUd5/JMdXNgvhGd+Y71jpRvjMfuod+/ezd69e09/fmqaU4ClS5eefn/eeXVrIhQVFdGjR90ppM2ZY7q4uBh/f3+CgoLIz89n5cqVAIwaNYrU1FRSU1OlpIVwsZ05Rdy1cAv9QwN506LHSjfGY3Z9NDTN6fLlyzlx4gSxsbH4+vqyePFioO5Fw2uvvZZOnTpx8cUXk5mZ6dD9DB06lPj4eAYOHEjPnj0ZM2aMMx+WEKIJOfZjpTu082HezBEE+vmYHanZPKaoExISWLduXb2XPfzwwzz//PO/+NqUKVOYMmXKr6575i6QM6WkpJxeOGD+/PkOZWpoW0IIY5yaV/pkZS0f3Xke3YKse6x0YzymqIUQnqW8qpZb52/iwLFS5s0cycBuHcyOdM48vqhlgVohWp+qGht3LNzC1sMn+Ne0YVzQz/rHSjfG44taCNG61No09y9NZfWeozz/2xiuiA0zO1KLuddLn0II0QitNY9/vJ0vt+fy58sHMXVEL7MjGUKKWgjRKmit+cfKXSzd/DN3J/bl92P7mB3JMFLUQohW4c2U/cxZc4AZ50Xw4KX9zY5jKI8qaitMc3qKzWbjj3/8I9HR0cTExDBixAiHj9UWQvzS+z8e4sVVu/lNfA+evHKIW5116AiPeTHRKtOcnrJ06VJycnJIS0vDy8uLrKysRk9NF0LU79Ofsnnisx2MH9SVF66JxcurdZU0eNCI2mrTnObm5hIWFoaXV923IDw8nE6dOhn9sIVo1b5Nz+fBj7YxqndnXr/e/U4Nd5QpI+rnNz7PruO7mnWb2tpavL29G7x8YOeBPDry0QYvt9o0p7/73e+44IILWLt2LUlJSUyfPp34+PhmPSdCeLL1+wu464OtDOnegbk3jcDPp+F+cHet889PPU5Nczpnzhy6dOnC1KlTT5/qfeY0p+vXrwfqpjm97LLLiImJ4cUXX2Tnzp2nt+XINKfDhg0jPj6enTt3kp6e/qvrhIeHs3v3bv7xj3/g5eVFUlIS3333nYGPWIjWKy2rkNsWbCKic3vm3zzSsmsdGsWUR9fYyLchJa1wmlNfX18mTpzIxIkTCQ0N5dNPPyUpKalFj1GI1m5vfgk3vbuRTv5tef/WUXT2b2t2JKdzaEStlDqolNqulEpVSm12dihnsNo0p1u3biUnJweoOwIkLS3tdB4hRP1+Pn6S6e9soI23F4tuG+W2kyw1V3NG1Ila62NOS+JkVpvm9MiRI/z+97+nsrISgJEjR3L33Xcb82CFaIWOFFcw/Z0NVFTbWHr7aCKCPecoqda9Y+cMVpvmdMKECUyYMKHJ6wkhoPBkFTPe3cjRkkoW3jbKrWfCOxdKa930lZTKBE4AGvi31npOPdeZBcwCCA0NTViyZMkvLg8KCqJv33Nfo6ypoz7OVXR0NKtXryY4OLjF23JWxn379lFUVGTY9kpLSwkICDBse84iOY3lrjkrajQvbqrgULGN+xP8GBJi/tEdznguExMTt2ith9d7oda6yTegh/19V2AbMLax6yckJOizpaen/+przVFcXNyi27uCszK29Lk7W3JysqHbcxbJaSx3zFlRXaOnz/1R9/7Tcr1ye655oc7ijOcS2Kwb6FSHXkzUWmfb3x8BPgFGtvzvhxBCNKym1sa9i1NZu/cYL1wzlAnR3cyOZJomi1op5a+UCjz1MXApsMPZwYQQnstm0/zp4+18tTOPJyYN5pqEcLMjmcqRFxNDgU/sxxe3AT7QWn/l1FRCCI+lteaZLzNYtiWLe5P6ccsFvc2OZLomi1prfQAY6oIsQgjB5/ur+WRfJjePieS+8f3MjmMJHnMKOVhrmtMnn3ySHj16EBcXx8CBA7nzzjux2WwtyiOEu5v3Qyaf7KvmmoRw/nrF4FY3Xem58pjjqK02zSnA/fffz0MPPYTNZmPs2LGsXr2axMTEFmUSwl19sOEwT32RTkKoN89dHdMqpys9Vx4zorbaNKdnqqqqoqKiQqY5FR5r0YZDPP7JdhIHdOGOob60aaXTlZ4rU0bUeX//O5UZzZvmtKa2luONnEziO2gg3R5/vMHLrTbNKcCrr77KwoULOXToEBMnTiQuLq4Zz4gQrcPCHw/xl093cPHArrw1fRjrv19rdiTL8Zg/W1ab5hTqdn2kpqZy5MgRysrKOPtsTiFau/ftJZ1kL2nfNuafdWhFpoyoGxv5NqS1TXN6Jh8fHyZMmMCaNWu47rrrWvQYhXAX768/yF8/28n4QV154wYp6cZ4zIjaatOcnklrzQ8//EBUVNS5P0Ah3Mh7UtLN4jFHfVhtmlP4//uoq6uriY2N5a677jLksQphZe+tP8gTn+1k/KBQ3rxhGG3beMx48dw1NAlIS97caVKmiIgIffToUUO2JZMyGUtyGssKOef/kKkjHl2ub1uwSVdW19Z7HSvkbIolJ2USQoiWmv9DJrM/38mlg0N543oZSTeHx+z6aMjBgwfNjiBEqzfvh0ye+iKdy4aE8q9pUtLN5dKi1lrLKaHNpB1Y2EEIK3v3+0yeXl5X0q9fPwwfOZml2Vz2jPn5+VFQUCDF0wxaawoKCvDz84wFPEXr846UtCFcNqIODw8nKyuLo0ePntPtKyoqLF9Yzsjo5+dHeLhnz8Ur3NPctQd45ssMJgzpxr+uj5eSbgGXFbWPjw+9e5/7vLIpKSnEx8cbmMh47pBRCFc4VdITo7vxf9OkpFvK419MFEIY6z9rDvDsigwuj+nGa9dJSRtBiloIYZg5a/bz9xW7uCImjH9eFyclbRApaiGEIf69ej//WCkl7QxS1EKIFnt79X6eW7mLK2LDeG1qnMwnbTApaiFEi7yVsp/nv9rFpNgw/ikl7RRS1EKIc/Zmyj5e+Go3Vw7tzqu/Gyol7STyrAohzsmpkp4sJe10MqIWQjSL1pqXvt7NG8n7mTy0O69ISTudw0WtlPIGNgPZWutJzoskhLCqWpvmL5/uYPHGw0wb2ZNnrorBW1YLd7rmjKjvBTKADk7KIoSwsMqaWu5fmsqK7XncOS6KRy4bIJOsuYhD/68opcKBK4C5zo0jhLCissoabluwmRXb8/jz5YN4dMJAKWkXUo7MZqeUWgb8AwgEHqpv14dSahYwCyA0NDTB6BW1S0tLCQgIMHSbRnOHjCA5jdbac5ZWaV7ZUkFmkY1bottyYbiPE9KdcX9u8Hw6I2NiYuIWrfXwei9saOmXU2/AJOBN+8fjgOVN3aa+pbhaylOX53EGyWms1pwzp/CkTno5Rff78wr91Y5c40PVwx2eT1cvxeXIPuoxwGSl1OWAH9BBKbVQaz3dgD8iQgiLOnC0lBvf2UhReTULbh7JeVHBZkfyWE3uo9ZaP6a1DtdaRwLXAf+TkhaidduRXcS1b6+norqWJbNGS0mbTI6jFkL8wvr9Bfz+vc0EtfPh/VtH0qeLtfcXe4JmFbXWOgVIcUoSIYTpvt6Zx92Lf6JX5/a8f+tIwoLamR1JICNqIYTdR5t/5tH/phEb3pF5M0fQyb+t2ZGEnRS1EOL0qiwX9gvh7ekJ+PtKNViJfDeE8GBaa15YtZu3UvZzRUwYr0wdim8bb7NjibNIUQvhoerm7djO4o0/c/2oXvxtSrTM22FRUtRCeKDKmlruW5LKyh153J3Ylwcv7S+nhFuYFLUQHqa0sobb39/MD/sK+MsVg7jtwj5mRxJNkKIWwoMcL6vi5nkb2ZFTzMvXDuW3CeFmRxIOkKIWwkMUlNu49u11/HyinLenJ3DJ4FCzIwkHOTR7XnPFBgfrLy6/wtBtFhYW0rFjR0O3aTR3yAiS02jukLO8upad2UVoYEC3QDr4OXcGvJZwh+fzaGAAw99809BtKqUanD1PRtRCtHIlFTXszi9BoxncPQj/tvJr726c8h1r27s3Ee+/Z+g2M1NSGDpunKHbNJo7ZATJaTQr5/z0p2weWZZGj1HtuH2QjcFXXGx2pCZZ+fk8JTMlxaX3JytSCtEKaa155Zs93Lc0lfheHfnkrvPp5i+/7u5K/gcSopWpqK7l4WVpfLEth2sTwnn2NzG0bSMl7c6kqIVoRY6VVjLrvc1sPVzIIxMGcOdFUXIiSysgRS1EK7Env4Rb5m/iWGklb90wjIkxYWZHEgaRohaiFVi95yh3L9qKX1tvPrz9PGLDO5odSRhIiloIN/f+j4d48vOd9A8N5J2bhtO9o0z239pIUQvhpmptmme+TGfeDwdJGtiV16bFEyDzSLdK8l0Vwg2VVtbwx8U/8b9dR7hlTG/+fMUgmaK0FZOiFsLNZBeWc+v8Tew9UsozV0UzfXSE2ZGEk0lRC+FGtv1cyG3vbaaiqpZ5M0cwtn8XsyMJF5CiFsJNrNieywMfphIS4MsHt42iX2ig2ZGEi0hRC2FxWmveTNnPi6t2M6xXR+bMGE5IgK/ZsYQLNVnUSik/YA3ga7/+Mq31bGcHE0JAVY2Nxz/ZzrItWUwe2p0XronFz0cWn/U0joyoK4GLtdalSikf4Hul1Eqt9Y9OziaERztRVsXtC7ewMfM4943vx71J/eR0cA/VZFHrupUFSu2f+tjfjF9tQAhx2oGjpdwyfxM5hRW8dl0cU+J6mB1JmMihFV6UUt7AFqAv8IbW+tF6rjMLmAUQGhqasGTJEkODlpaWEhAQYOg2jeYOGUFyGs3onBkFtbyeWoGXgj/G+9GvkzG7Ojz1+XQGZ2RMTExscIUXtNYOvwEdgWQgurHrJSQkaKMlJycbvk2juUNGrSWn0YzKabPZ9H/W7Nd9HvtSJ72cog8XlBmy3VM87fl0JmdkBDbrBjq1WUd9aK0LlVLJwARgR4v+fAghTiutrOHRZWl8uT2Xy4aE8uK1Qy29rqFwLUeO+ugCVNtLuh1wCfC805MJ4SH25pdw+8ItHDxWxmMTBzJrbB950VD8giMj6jBggX0/tRfwodZ6uXNjCeEZPt+Ww5/+m0b7tm1YdNtozosKNjuSsCBHjvpIA+JdkEUIj1FVY+PvKzKYv+4gwyM68cYNwwjt4Gd2LGFRcmaiEC6WV1TBHz7YypZDJ7hlTG8eu3wgPt6ypqFomBS1EC60bt8x7ln8ExXVtbx+fTyTYrubHUm4ASlqIVxAa83bqw/w4qpd9OkSwNvTh9G3q0yqJBwjRS2EkxWVV/PQR9v4Jj2fSbFhPP/bWPxlJRbRDPLTIoQTZeQWc8fCLWSfKGf2lYOZeX6kHHonmk2KWggn+e+WLP786XaC2vmwZNZohkd2NjuScFNS1EIYrLKmlqe+SOeDDYcZ3acz/5o2jC6BMn+0OHdS1EIYKOvESe5atJW0rCLuuCiKhy7tTxs59E60kBS1EAZZveco9y75idpazb9vTOCyId3MjiRaCSlqIVrIpjWvfbuXf363hwGhgbw1PYHeIf5mxxKtiBS1EC1QeLKKf26pJO3YHq6O78Gzv4mhXVtZKksYS4paiHP044ECHvxwG/lFtTxzVTQ3jOolh94Jp5CiFqKZKmtqeeWbPcxZc4CIzu15fLQf00dHmB1LtGJS1EI0w578Eu5dkkpGbjHTRvbiL1cMYtP6782OJVo5KWohHGCzaeavO8hzX+0i0LcNc2cMZ/zgULNjCQ8hRS1EE/KKKnh42TbW7j1G0sCuPPfbWDmBRbiUFLUQjfgyLZfHP9leN9H/b2KYNrKnvGAoXE6KWoh6FFdU8+TnO/l4azZDe3bk1d8NpU+XALNjCQ8lRS3EWTZmHuf+pankFpXzx6R+3HNxX1mBRZhKiloIu6oaG69+u4e3V++nV+f2fHTH+SREdDI7lhBS1EIA7DtSd9jdzpxirhvRk79OGiyT+wvLkJ9E4dG01ixYd5B/rNyFv28bmUxJWFKTRa2U6gm8B4QCGpijtX7N2cGEcLb84goeXpbGmj1HGTegCy9cE0vXQD+zYwnxK46MqGuAB7XWW5VSgcAWpdQ3Wut0J2cTwmm+2pHLnz7eTkV1LX+bMoTpoyPksDthWU0WtdY6F8i1f1yilMoAegBS1MLtlFRU89QX6SzbkkVMjyD+eV0cUXLYnbA4pbV2/MpKRQJrgGitdfFZl80CZgGEhoYmLFmyxMCYUFpaSkCAtX+h3CEjeG7OPSdq+U9aJcfKNZP6+DClrw9tvFo+ivbU59NZ3CGnMzImJiZu0VoPr/dCrbVDb0AAsAW4uqnrJiQkaKMlJycbvk2juUNGrT0vZ+HJKv3Yx2k64tHl+oLnv9ObMgsM2e4pnvZ8Ops75HRGRmCzbqBTHTrqQynlA/wXWKS1/tiYvx9COJfWmuVpuTz1RTrHyyq59YLePHBJfznsTrgdR476UMA7QIbW+hXnRxKi5X4+fpK/fraDlN1HiekRxPybRxDdI8jsWEKcE0eGFmOAG4HtSqlU+9ce11qvcFoqIc5Rda2Nd7/P5NVv9+ClFH+dNJibzouQlcCFW3PkqI/vATluSVhe6s+FPPbxdjJyixk/KJSnpwyhe8d2ZscSosVkZ51weyUV1by0ajfv/XiI0EA/3p6ewIRoObtQtB5S1MJtaa1ZtTOP2Z/v5EhJJTedF8mDl/Yn0M/H7GhCGEqKWril7MJyZn+2g28zjjAorAP/vnE4cT07mh1LCKeQohZupabWxoL1h3j5691oDY9fPpBbxvSWFwtFqyZFLdzG9qwiHvskjR3ZxYwb0IW/TYmmZ+f2ZscSwumkqIXllVXW8PLXe5i/LpPgAF9evz6eK2LCZBIl4TGkqIWlfZuezxOf7SCnqIIbRvXikQkDCWonLxYKz9KsSZkcFdI/RF/5f1caus3CwkI6duxo6DaN5g4ZwT1yVtXY2JtXSEmVpn1bb3qHBBDoZ81xhTs8nyA5jRRwMoB/Xf0vQ7eplGpwUiZr/uQLj1Vr0+QWlZNbVIHWml6d2xMW1A7ZyyE8mVOKOrJDJPMmzDN0mykpKYwbN87QbRrNHTKCNXPW1Nr4cHMWr3yzh2OllUyKDeOijoVce/nFZkdrkhWfz/pITuOkpKS49P5kRC1MpbUmZfdR/r4ig71HShkR2Yn/zEggvlcnl/8yCGFVUtTCNDuyi/j7igzW7S8gMrg9b09P4LIhoXI0hxBnkaIWLpdTWM5LX+/mk5+y6djOhyevHMz1oyJo20ZOWhGiPlLUwmVKKqp5K2U/73yfiQZuHxvFXYlRdJC5OYRolBS1cLrqWhtLNh7mn9/upaCsit/E9+DBS/sT3knOKhTCEVLUwmm01nyTns9zK3dx4FgZo/t0Zv7lg4kJl5VWhGgOKWrhFNt+LuTZFRlszDxOVBd/5s4YTtKgrvJCoRDnQIpaGOrn4yd5cdVuPt+WQ0hAW565KprrRvSU2e2EaAEpamGIopPVvJGyj/k/HMTLC+65uC+3XxRFgKz4LUSLyW+RaJHSyhoW/XiIt1bvp6i8mt8OC+fBS/sTFiRrFQphFClqcU4KT1Yxf91B5v1wkKLyai7sF8JjEwcxuHsHs6MJ0epIUYtmOVJSwTvfZ7Jw/SHKqmq5ZHAof0jsK8tgCeFEUtTCIdmF5fx79X6WbvqZ6lobk2K7c1diFAO7yQhaCGdrsqiVUu8Ck4AjWuto50cSVnLgaClvpeznk5+yUQqujg/njnFR9A7xNzuaEB7DkRH1fOB14D3nRhFWkp5TzBsp+1ixPZe23l5MHx3BrLF96N5RXiQUwtWaLGqt9RqlVKQLsggL2Hr4BG/8bx/f7TpCgG8b7rgoilsv6E1IgK/Z0YTwWA4txWUv6uWN7fpQSs0CZgGEhoYmLFmyxKiMAJSWlhIQEGDoNo3mDhnh1zm11mQct/HF/ioyjtvw94FLI3wYH+GDv495ZxK66/NpVZLTOM7ImJiY2OBSXGitm3wDIoEdjlxXa01CQoI2WnJysuHbNJo7ZNT6/+e02Wz6m515esrr3+uIR5frEc98o/+zZr8urag2N6Cduz2fVic5jeOMjMBm3UCnylEfHsimNV9sy+GN5H3syishvFM7nrkqmmsSwvHz8TY7nhDiLFLUHqSkoppPU3N4Y205eSd/IqqLPy9fO5TJcd3xkbk4hLAsRw7PWwyMA0KUUlnAbK31O84OJoyzI7uIRRsO81lqNieraons4MWbN8QzYUg3vLxkNjshrM6Roz6muSKIMFZ5VS1fpOWwaMNhtv1ciJ+PF1fGdueG0RGc2PcTiTFhZkcUQjhIdn20MnvzS1i04TD/3ZpFSUUN/boGMPvKwVwdH05Q+7olr1L2yyhaCHciRd0KVNbU8tWOPBZtOMzGzOO09fZiYkw3bhgVwYjITjJZvxBuTorajR0qKOODjYf5aHMWx8uqiAhuz2MTB3JNQjjBcoKKEK2GFLWbqa618V1GPos2HGbt3mN4eykuGRTKDaN7MSYqRF4cFKIVkqJ2E9mF5SzdeJglm37mSEkl3YP8eOCS/kwd0ZPQDn5mxxNCOJEUtYXV2jRr9hxl0YZD/G/XETSQOKArN4zqxbgBXfGW0bMQHkGK2mJqam1szDzOl9tzWbUzj2OlVYQE+HLXuL5MHdGTnp3bmx1RCOFiUtQWUFNrY8Opct6RR0FZFe18vLl4UFeujA0jaVConDkohAdzaPa85hoeGaQ3z77A0G0WFhbSsWNHQ7dptOZk1GiKy2soKKvkeFkVNTaNl1J0au9DZ/+2dGzfFm8nHVbnDs8lSE6jSU7jZNV0Ivz3Cw3dplKqwdnzZETtQhpNUXk1x8uqflXOwf5tCXJiOQsh3JdzijqkH9z8paGbTE1JYdy4cYZu02j1ZayutbF+fwEr7PucT5ysxr+tN0mDQrk8JoxxA7q4fMY6d3guQXIaTXIaZ19KCuEuvD8ZUTtBda2NdfsLWJGWy6r0PArt5Tx+cF05X9Tf9eUshHBfUtQGqaiuJe1oDSuWbePr9HwKT1YT4NuG8YO6cnlMGGOlnIUQ50iK+hzV1NpIyy5i/f4C1u0/xuaDJ6issRHom3d65HxhvxApZyFEi0lRO8hm02TkFduLuYCNmccprawBYFBYB6aPjiDwZA53Xp2IbxspZyGEcaSoG6C15sCxMtbtL2DdvmP8eKCAEyerAejTxZ+r4rtzflQIo/sE09m/LQApKUekpIUQhpOiPkPWiZOs219wendGfnElAN2D/EgaFMr5UcGcHxVCtyCZW0MI4ToeXdRHSipYf7qYCzh8/CQAIQFtOS8qxF7MwfTq3F7mdBZCmMZjivp4WRUZucVk5BaTnlvM9qwi9h4pBSDQrw2j+wRz85hIxvQNoV/XAClmIYRltLqirrVpDhaU1RVyTrG9nEvIK644fZ2ugb4M7t6B3yaEc35UMEO6B8lMdEIIy3Lroi6trGHX6VFyCem5xezJK6G8uhaANl6Kvl0DOC8qmEFhgQwK68CgsA6EyOonQgg34hZFrbXmWLmNr3fmkZFbUjdKzivmUMHJ09cJaufDoLBApo3sdbqU+4UGyFEYQgi3Z4miPllVQ25RBbmFFeQWlZNXVEFOUQV5ReXkFlWQfaKcksoaYAtKQWSwP0O6d+CaYeEM7l43Sg4L8pP9ykKIVsmholZKTQBeA7yBuVrr5xy9g7JKewnbSzfvrI9zCssprqj51e2C/dsS1tGP8E7tGdm7MxTlMuWi4QzsFoi/ryX+vgghhEs02XhKKW/gDeASIAvYpJT6XGud3tBtDh4r47JX15BTVE5JPSUcEtCWsKB29OxcV8JhQe0IC/KjW5Af3YPa0bWD769OvU5JOUZCRKfmPj4hhHB7jgxNRwL7tNYHAJRSS4ApQINFXWPTRAS3Z3SfzoR1tJdwBz+6d6wrYdlvLIQQjmtyhRel1DXABK31bfbPbwRGaa3vPut6s4BZAKGhoQlLliwxNGhpaSkBAQGGbtNo7pARJKfRJKex3CGnMzImJiY2uMILWutG34BrqNsvferzG4HXG7tNQkKCNlpycrLh2zSaO2TUWnIaTXIayx1yOiMjsFk30KmOrJiaDfQ84/Nw+9eEEEK4gCNFvQnop5TqrZRqC1wHfO7cWEIIIU5p8sVErXWNUupuYBV1h+e9q7Xe6fRkQgghAAePo9ZarwBWODmLEEKIejiy60MIIYSJpKiFEMLipKiFEMLipKiFEMLimjwz8Zw2qtRR4JDBmw0Bjhm8TaO5Q0aQnEaTnMZyh5zOyBihte5S3wVOKWpnUEpt1g2dXmkR7pARJKfRJKex3CGnqzPKrg8hhLA4KWohhLA4dyrqOWYHcIA7ZATJaTTJaSx3yOnSjG6zj1oIITyVO42ohRDCI0lRCyGExVm6qJVSPZVSyUqpdKXUTqXUvWZnaoxSylsp9ZNSarnZWRqilOqolFqmlNqllMpQSp1ndqb6KKXut3/PdyilFiul/MzOBKCUelcpdUQpteOMr3VWSn2jlNprf2/64p4N5HzR/n1PU0p9opTqaGLEejOecdmDSimtlAoxI9tZWerNqZS6x/587lRKveDMDJYuaqAGeFBrPRgYDfxBKTXY5EyNuRfIMDtEE14DvtJaDwSGYsG8SqkewB+B4VrraOqm173O3FSnzQcmnPW1PwHfaa37Ad/ZPzfbfH6d8xsgWmsdC+wBHnN1qLPM59cZUUr1BC4FDrs6UAPmc1ZOpVQidWvHDtVaDwFecmYASxe11jpXa73V/nEJdaXSw9xU9VNKhQNXAHPNztIQpVQQMBZ4B0BrXaW1LjQ1VMPaAO2UUm2A9kCOyXkA0FqvAY6f9eUpwAL7xwuAq1yZqT715dRaf621rrF/+iN1qzWZpoHnEuBV4BHAEkc6NJDzTuA5rXWl/TpHnJnB0kV9JqVUJBAPbDA5SkP+Sd0Pl83kHI3pDRwF5tl30cxVSvmbHepsWuts6kYoh4FcoEhr/bW5qRoVqrXOtX+cB4SaGcZBtwArzQ5xNqXUFCBba73N7CxN6A9cqJTaoJRarZQa4cw7c4uiVkoFAP8F7tNaF5ud52xKqUnAEa31FrOzNKENMAx4S2sdD5RhjX/Tf8G+j3cKdX9YugP+Sqnp5qZyjH2RUkuMBBuilPozdbsVF5md5UxKqfbA48ATZmdxQBugM3W7ZB8GPlRKKWfdmeWLWinlQ11JL9Jaf2x2ngaMASYrpQ4CS4CLlVILzY1UrywgS2t96r+SZdQVt9WMBzK11ke11tXAx8D5JmdqTL5SKgzA/t6p/wa3hFJqJjAJuEFb7ySKKOr+OG+z/y6FA1uVUt1MTVW/LOBj+wLiG6n7T9ppL3xauqjtf6HeATK01q+YnachWuvHtNbhWutI6l70+p/W2nIjQK11HvCzUmqA/UtJQLqJkRpyGBitlGpv/xlIwoIvep7hc+Am+8c3AZ+ZmKVBSqkJ1O2em6y1Pml2nrNprbdrrbtqrSPtv0tZwDD7z63VfAokAiil+gNtceKMf5YuaupGqjdSN0JNtb9dbnYoN3cPsEgplQbEAX83N86v2Uf8y4CtwHbqfk4tcVqxUmoxsB4YoJTKUkrdCjwHXKKU2kvdfwPPmZkRGsz5OhAIfGP/XXrbghktp4Gc7wJ97IfsLQFucuZ/KHIKuRBCWJzVR9RCCOHxpKiFEMLipKiFEMLipKiFEMLipKiFEMLipKiFEMLipKiFEMLi/h9U1xIFi5OW6QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.grid(True)\n",
    "plt.plot(df['swin'], label='Swin-T')\n",
    "plt.plot(df['sparta_tiny'], label='SparTa-T')\n",
    "plt.plot(df['sparta_small'], label='SparTa-S')\n",
    "plt.plot(df['sparta_base'], label='SparTa-B')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(1, 17)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
